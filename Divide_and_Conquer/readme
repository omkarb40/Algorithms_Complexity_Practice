# Closest Point to Origin

Given an array of points on the 2D plane, where each point is represented as [x, y], and an integer k, return the k closest points to the origin (0, 0) by Euclidean distance.

The Euclidean distance between two points (x1, y1) and (x2, y2) is: √((x1 - x2)² + (y1 - y2)²)

You may return the answer in any order. The answer is guaranteed to be unique (except for the order that it is in).

Example to illustrate: - If points = [[1,3],[-2,2]] and k = 1, the point [-2,2] is closer (distance = √8) than [1,3] (distance = √10), so you would return [[-2,2]].

Solve this problem using divide and conquer.

Input Format

The first line contains an integer k, representing how many closest points to return.
The next lines contain space-separated integers x and y, representing the coordinates of a point. The total number of points is implicitly given by the number of lines following k.

Constraints
1 ≤ K ≤ total number of points ≤ 10^4, and -10^4 ≤ x, y ≤ 10^4

Output Format

We only want the x, y coordinate closest k points from the origin

Sample Input 0

1
2 3
10 10
Sample Output 0

2 3
Sample Input 1

1
1 3
-2 2
Sample Output 1

-2 2